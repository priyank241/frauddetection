{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1399887,"sourceType":"datasetVersion","datasetId":817870}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Fraud Detection Model Training\n## Overview\nThis notebook trains a machine learning model to predict fraudulent transactions based on various features like transaction time, amount, location,etc.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:58:57.384521Z","iopub.execute_input":"2025-02-28T09:58:57.385237Z","iopub.status.idle":"2025-02-28T09:58:57.780565Z","shell.execute_reply.started":"2025-02-28T09:58:57.385189Z","shell.execute_reply":"2025-02-28T09:58:57.779704Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/fraud-detection/fraudTrain.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:58:57.781696Z","iopub.execute_input":"2025-02-28T09:58:57.782127Z","iopub.status.idle":"2025-02-28T09:59:07.192602Z","shell.execute_reply.started":"2025-02-28T09:58:57.782095Z","shell.execute_reply":"2025-02-28T09:59:07.191697Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:07.524446Z","iopub.execute_input":"2025-02-28T09:59:07.524772Z","iopub.status.idle":"2025-02-28T09:59:07.560006Z","shell.execute_reply.started":"2025-02-28T09:59:07.524750Z","shell.execute_reply":"2025-02-28T09:59:07.559176Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 15012 entries, 2449 to 566921\nData columns (total 23 columns):\n #   Column                 Non-Null Count  Dtype  \n---  ------                 --------------  -----  \n 0   Unnamed: 0             15012 non-null  int64  \n 1   trans_date_trans_time  15012 non-null  object \n 2   cc_num                 15012 non-null  int64  \n 3   merchant               15012 non-null  object \n 4   category               15012 non-null  object \n 5   amt                    15012 non-null  float64\n 6   first                  15012 non-null  object \n 7   last                   15012 non-null  object \n 8   gender                 15012 non-null  object \n 9   street                 15012 non-null  object \n 10  city                   15012 non-null  object \n 11  state                  15012 non-null  object \n 12  zip                    15012 non-null  int64  \n 13  lat                    15012 non-null  float64\n 14  long                   15012 non-null  float64\n 15  city_pop               15012 non-null  int64  \n 16  job                    15012 non-null  object \n 17  dob                    15012 non-null  object \n 18  trans_num              15012 non-null  object \n 19  unix_time              15012 non-null  int64  \n 20  merch_lat              15012 non-null  float64\n 21  merch_long             15012 non-null  float64\n 22  is_fraud               15012 non-null  int64  \ndtypes: float64(5), int64(6), object(12)\nmemory usage: 2.7+ MB\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Dataset Description\nThe dataset consists of transaction records with the following features:\n\n| Feature Name           | Description                          |\n|------------------------|--------------------------------------|\n| `trans_date_trans_time` | Timestamp of the transaction       |\n| `merchant`            | Merchant name                       |\n| `category`            | Category of transaction             |\n| `gender`              | Gender of the customer              |\n| `city`, `state`       | Location of the transaction         |\n| `is_weekend`          | Indicates if transaction is on a weekend |\n| `amt`                 | Transaction amount                  |\n| `lat`, `long`         | Customer's location coordinates     |\n| `city_pop`            | City population                     |\n| `merch_lat`, `merch_long` | Merchant's location coordinates |\n\nThe target variable is:\n- `fraud`: 1 for fraudulent transactions, 0 for legitimate transactions.\n","metadata":{}},{"cell_type":"code","source":"df2 = df\ndf = df.iloc[:,1:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:07.826734Z","iopub.execute_input":"2025-02-28T09:59:07.827124Z","iopub.status.idle":"2025-02-28T09:59:07.838143Z","shell.execute_reply.started":"2025-02-28T09:59:07.827087Z","shell.execute_reply":"2025-02-28T09:59:07.837295Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"cols_to_drop = ['cc_num','first','last','street','zip','job','trans_num','unix_time','dob']\ndf = df.drop(cols_to_drop,axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:07.882726Z","iopub.execute_input":"2025-02-28T09:59:07.882955Z","iopub.status.idle":"2025-02-28T09:59:07.889540Z","shell.execute_reply.started":"2025-02-28T09:59:07.882937Z","shell.execute_reply":"2025-02-28T09:59:07.888606Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:07.890465Z","iopub.execute_input":"2025-02-28T09:59:07.890784Z","iopub.status.idle":"2025-02-28T09:59:07.914080Z","shell.execute_reply.started":"2025-02-28T09:59:07.890758Z","shell.execute_reply":"2025-02-28T09:59:07.913270Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df['year'] = df['trans_date_trans_time'].dt.year\ndf['month'] = df['trans_date_trans_time'].dt.month\ndf['day'] = df['trans_date_trans_time'].dt.day\ndf['hour'] = df['trans_date_trans_time'].dt.hour\ndf['weekday'] = df['trans_date_trans_time'].dt.weekday  # Monday=0, Sunday=6\ndf['is_weekend'] = df['weekday'].isin([5, 6]).astype(int)  # 1 for Sat/Sun, 0 otherwise\ndf['day_of_year'] = df['trans_date_trans_time'].dt.dayofyear\ndf['week_of_year'] = df['trans_date_trans_time'].dt.isocalendar().week\ndf['quarter'] = df['trans_date_trans_time'].dt.quarter\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:07.914914Z","iopub.execute_input":"2025-02-28T09:59:07.915142Z","iopub.status.idle":"2025-02-28T09:59:07.944359Z","shell.execute_reply.started":"2025-02-28T09:59:07.915123Z","shell.execute_reply":"2025-02-28T09:59:07.943727Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"cat_cols = ['merchant','category','gender','city','state','is_weekend']\nnum_cols = ['amt', 'lat', 'long', 'city_pop', 'merch_lat', 'merch_long']+['hour', 'day', 'weekday', 'day_of_year', 'week_of_year', 'month', 'quarter','year']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:07.945187Z","iopub.execute_input":"2025-02-28T09:59:07.945417Z","iopub.status.idle":"2025-02-28T09:59:07.949758Z","shell.execute_reply.started":"2025-02-28T09:59:07.945386Z","shell.execute_reply":"2025-02-28T09:59:07.949000Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"from scipy.stats import chi2_contingency\n\ndef check_chi2(df, target, cat_columns):\n    results = {}\n\n    for cat_column in cat_columns:\n        # Create a contingency table\n        contingency_table = pd.crosstab(df[cat_column], df[target])\n        \n        # Perform Chi-Square test\n        chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n        \n        # Interpretation\n        if p_value <= 0.05:\n            results[cat_column] = \"Columns correlated\"\n        else:\n            results[cat_column] = \"Columns not correlated\"\n    \n    return results\n\ntarget = 'is_fraud'\ncat_results = check_chi2(df, target, cat_cols)\ncat_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:07.950520Z","iopub.execute_input":"2025-02-28T09:59:07.950746Z","iopub.status.idle":"2025-02-28T09:59:08.052435Z","shell.execute_reply.started":"2025-02-28T09:59:07.950728Z","shell.execute_reply":"2025-02-28T09:59:08.051635Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'merchant': 'Columns correlated',\n 'category': 'Columns correlated',\n 'gender': 'Columns correlated',\n 'city': 'Columns correlated',\n 'state': 'Columns correlated',\n 'is_weekend': 'Columns correlated'}"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"from scipy.stats import f_oneway\n\ndef check_anova(df, target, num_columns):\n    results = {}\n    \n    for num_column in num_columns:\n        grp_data = df.groupby(target)[num_column].apply(list)\n        f_statistic, p_value = f_oneway(*grp_data)\n        \n        if p_value <= 0.05:\n            results[num_column] = \"Correlated\"\n        else:\n            results[num_column] = \"Not correlated\"\n    \n    return results\n\nanova_results = check_anova(df, 'is_fraud', num_cols)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:08.053187Z","iopub.execute_input":"2025-02-28T09:59:08.053453Z","iopub.status.idle":"2025-02-28T09:59:08.109725Z","shell.execute_reply.started":"2025-02-28T09:59:08.053422Z","shell.execute_reply":"2025-02-28T09:59:08.108915Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"for i, j in anova_results.items():\n    print(i, ' : ',j)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:08.110803Z","iopub.execute_input":"2025-02-28T09:59:08.111090Z","iopub.status.idle":"2025-02-28T09:59:08.117777Z","shell.execute_reply.started":"2025-02-28T09:59:08.111063Z","shell.execute_reply":"2025-02-28T09:59:08.115896Z"}},"outputs":[{"name":"stdout","text":"amt  :  Correlated\nlat  :  Not correlated\nlong  :  Correlated\ncity_pop  :  Correlated\nmerch_lat  :  Not correlated\nmerch_long  :  Correlated\nhour  :  Correlated\nday  :  Correlated\nweekday  :  Not correlated\nday_of_year  :  Correlated\nweek_of_year  :  Correlated\nmonth  :  Correlated\nquarter  :  Correlated\nyear  :  Correlated\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"df = df.drop(['trans_date_trans_time'],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:08.121044Z","iopub.execute_input":"2025-02-28T09:59:08.121241Z","iopub.status.idle":"2025-02-28T09:59:08.135481Z","shell.execute_reply.started":"2025-02-28T09:59:08.121225Z","shell.execute_reply":"2025-02-28T09:59:08.134865Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"[ col for col in df.columns if col not in num_cols and col not in cat_cols]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:08.136318Z","iopub.execute_input":"2025-02-28T09:59:08.136503Z","iopub.status.idle":"2025-02-28T09:59:08.154438Z","shell.execute_reply.started":"2025-02-28T09:59:08.136487Z","shell.execute_reply":"2025-02-28T09:59:08.153745Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"['is_fraud']"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"## Data Preprocessing  \n- Encoding categorical features  \n- Scaling numerical features  \n- Splitting into train and test sets  \n","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:08.155112Z","iopub.execute_input":"2025-02-28T09:59:08.155314Z","iopub.status.idle":"2025-02-28T09:59:08.235807Z","shell.execute_reply.started":"2025-02-28T09:59:08.155297Z","shell.execute_reply":"2025-02-28T09:59:08.235147Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"num_transformer = StandardScaler()\ncat_transformer = OneHotEncoder(handle_unknown='ignore')  # Ignore unseen categories\n\n# ðŸ”¹ Combine transformations into a ColumnTransformer\npreprocessor = ColumnTransformer([\n    ('num', num_transformer, num_cols),\n    ('cat', cat_transformer, cat_cols)\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:08.236457Z","iopub.execute_input":"2025-02-28T09:59:08.236850Z","iopub.status.idle":"2025-02-28T09:59:08.240818Z","shell.execute_reply.started":"2025-02-28T09:59:08.236829Z","shell.execute_reply":"2025-02-28T09:59:08.239868Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"X = df[num_cols + cat_cols]  # Features\ny = df['is_fraud']           # Target variable\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:08.241602Z","iopub.execute_input":"2025-02-28T09:59:08.241968Z","iopub.status.idle":"2025-02-28T09:59:08.271288Z","shell.execute_reply.started":"2025-02-28T09:59:08.241911Z","shell.execute_reply":"2025-02-28T09:59:08.270656Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"X_train_transformed = preprocessor.fit_transform(X_train)\n\n# ðŸ”¹ Transform test data (without refitting)\nX_test_transformed = preprocessor.transform(X_test)\n\n# ðŸ”¹ Convert transformed data into DataFrames (Optional)\nX_train_df = pd.DataFrame(X_train_transformed.toarray(), columns=preprocessor.get_feature_names_out())\nX_test_df = pd.DataFrame(X_test_transformed.toarray(), columns=preprocessor.get_feature_names_out())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:08.271980Z","iopub.execute_input":"2025-02-28T09:59:08.272177Z","iopub.status.idle":"2025-02-28T09:59:08.631377Z","shell.execute_reply.started":"2025-02-28T09:59:08.272162Z","shell.execute_reply":"2025-02-28T09:59:08.630710Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## Model Selection and Training\n- Selected model: [Random Forest ]\n- Performance metrics: Accuracy, Precision, Recall,Classification Report\n","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\n# ðŸ”¹ Initialize and train the Random Forest classifier\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model.fit(X_train_df, y_train)\n\n# ðŸ”¹ Make predictions\ny_pred = rf_model.predict(X_test_df)\n\n# ðŸ”¹ Evaluate performance\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n\n# ðŸ”¹ Print results\nprint(f\"âœ… Accuracy: {accuracy:.4f}\\n\")\nprint(\"ðŸ“Œ Confusion Matrix:\")\nprint(conf_matrix)\nprint(\"\\nðŸ“Œ Classification Report:\")\nprint(class_report)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:08.632185Z","iopub.execute_input":"2025-02-28T09:59:08.632397Z","iopub.status.idle":"2025-02-28T09:59:16.437599Z","shell.execute_reply.started":"2025-02-28T09:59:08.632380Z","shell.execute_reply":"2025-02-28T09:59:16.436737Z"}},"outputs":[{"name":"stdout","text":"âœ… Accuracy: 0.9677\n\nðŸ“Œ Confusion Matrix:\n[[1465   37]\n [  60 1441]]\n\nðŸ“Œ Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.96      0.98      0.97      1502\n           1       0.97      0.96      0.97      1501\n\n    accuracy                           0.97      3003\n   macro avg       0.97      0.97      0.97      3003\nweighted avg       0.97      0.97      0.97      3003\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"## Model Deployment\n- Save model as a pickle (`.pkl`) file\n- Save preprocessor as a pickle (`.pkl`) file","metadata":{}},{"cell_type":"code","source":"import pickle\n\n# Assuming you have a preprocessor and a trained RandomForest model\nwith open(\"preprocessor.pkl\", \"wb\") as f:\n    pickle.dump(preprocessor, f)\n\nwith open(\"rf_model.pkl\", \"wb\") as f:\n    pickle.dump(rf_model, f)\n\nprint(\"Preprocessor and RandomForest model saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-28T09:59:16.440737Z","iopub.execute_input":"2025-02-28T09:59:16.441153Z","iopub.status.idle":"2025-02-28T09:59:16.494601Z","shell.execute_reply.started":"2025-02-28T09:59:16.441128Z","shell.execute_reply":"2025-02-28T09:59:16.493721Z"}},"outputs":[{"name":"stdout","text":"Preprocessor and RandomForest model saved successfully!\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}